\relax 
\citation{todoroki1998stacking}
\citation{liu2000permutation}
\citation{sivakumar1998optimum}
\citation{walker2003technique}
\citation{lin2004stacking}
\citation{kang2005minimum}
\citation{murugan2007target}
\citation{akbulut2008optimum}
\citation{YAN2020108014}
\citation{MENTGES2021108736}
\citation{lobo2007parameter}
\citation{liu1996evolutionary}
\citation{rodzin2016neuroevolution}
\providecommand \oddpage@label [2]{}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}\protected@file@percent }
\citation{massard1984computer}
\citation{reddy1987first}
\citation{fang1993design}
\citation{soeiro1994multilevel}
\citation{pelletier2006multi}
\citation{jadhav2007parametric}
\citation{omkar2008artificial}
\citation{choudhury2019failure}
\citation{watkins1987multicriteria}
\citation{martin1987optimum}
\citation{soares1995discrete}
\@writefile{toc}{\contentsline {section}{\numberline {II}classical lamination theory and failure criteria}{2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-A}}Classical Lamination Theory}{2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {II-A}1}Stress and Strain in a Lamina}{2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces The left diagram shows the local and global axis of an angle lamina, which is from a laminate as shown in the right diagram.\relax }}{2}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:lamina_local_and_global}{{1}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Model for angle ply laminate\relax }}{2}\protected@file@percent }
\newlabel{fig:angle-ply}{{2}{2}}
\newlabel{equ:stress-strain}{{3}{2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {II-A}2}Stress and Strain in a Laminate}{2}\protected@file@percent }
\newlabel{eq:force_and_moments}{{5}{2}}
\citation{cybenko1989approximation}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-B}}Failure criteria for a lamina}{3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {II-B}1}Maximum stress(MS) failure criterion}{3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Schematic failure surfaces for maximum stress and quadratic failure criteria\relax }}{3}\protected@file@percent }
\newlabel{fig:failure_surface}{{3}{3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {II-B}2}Tsai-Wu failure criterion}{3}\protected@file@percent }
\newlabel{eq:tsai_wu}{{8}{3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {II-B}3}Strength ratio}{3}\protected@file@percent }
\newlabel{eq:sr}{{10}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {III}Evolutionary Artificial Neural Network}{3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-A}}General neural network}{3}\protected@file@percent }
\citation{liu1996evolutionary}
\pgfsyspdfmark {pgfid3}{12462671}{44169254}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Network diagram for the two-layer neural network. The input, hidden, and output variables are represented by nodes, and the weight parameters are represented by links between the nodes. Arrows denote the direction of information flow through the network during forward propagation.\relax }}{4}\protected@file@percent }
\newlabel{fig:gnn}{{4}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-B}}Activation function}{4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-C}}Weights learning}{4}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {I}{\ignorespaces Examples of widely used activation functions in the design of an artificial neural network.\relax }}{4}\protected@file@percent }
\newlabel{tab:active_function}{{I}{4}}
\newlabel{tab:transfer_function}{{I}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Methodology}{4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces A general framework for evolutionary neural network, in which fitness refers to the corresponding value of objective function.\relax }}{4}\protected@file@percent }
\newlabel{fig:evolution}{{5}{4}}
\pgfsyspdfmark {pgfid5}{21350987}{41947589}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Diagram for modeling the target function of strength ratio calculating for an angle ply laminate.\relax }}{5}\protected@file@percent }
\newlabel{fig:gnn_for_clt}{{6}{5}}
\@writefile{lot}{\contentsline {table}{\numberline {II}{\ignorespaces The binary representation of parent 1, parent 2, and child corresponding to Fig.4\hbox {}(a), (b) and (c), with $i_1,i_2,\cdots  , I_{16}$ denote sixteen inputs and $h_1,h_2, \cdots  , h_{12}$ refer to nodes in the hidden layer. 1 represents an edge from the input node to hidden node, and 0 represents no edge from input nodes to hidden node.\relax }}{5}\protected@file@percent }
\newlabel{tab:binary-rep}{{II}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-A}}Search Space}{5}\protected@file@percent }
\citation{baker2017accelerating}
\citation{lecun1989backpropagation}
\pgfsyspdfmark {pgfid6}{11397888}{44274948}
\pgfsyspdfmark {pgfid7}{11512578}{36905184}
\pgfsyspdfmark {pgfid8}{11512578}{29535420}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Examples of three ANNs, with (a) and (b) as parent ANNs, and (c) as the child of (a) and (b). child c inherits the connection relationship part from parent 1 denoted by the darker dashed lines,and the rest from parent 2 denoted by the gray dashed line.\relax }}{6}\protected@file@percent }
\newlabel{fig:anns}{{7}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-B}}Search Strategy}{6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-C}}Performance estimation strategy}{6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {V}Experiment}{6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {V-A}}Dataset Preparation}{6}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {III}{\ignorespaces Comparison of the carbon/epoxy, graphite/epoxy, and glass/epoxy properties\relax }}{7}\protected@file@percent }
\newlabel{tab:mat}{{III}{7}}
\@writefile{lot}{\contentsline {table}{\numberline {IV}{\ignorespaces Examples of the training data\relax }}{7}\protected@file@percent }
\newlabel{tab:traing-data}{{IV}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {V-B}}ANN training and validation}{7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {V-C}}Genetic algorithm}{7}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {VI}Result and Discussion}{7}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Fitness and averaged sum-of-squares errors of the pre-trained artificial neural network as generations proceed.\relax }}{7}\protected@file@percent }
\newlabel{fig:ga_nn}{{8}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces The illustration of the behaviour of fitness on the training dataset during the training session.\relax }}{7}\protected@file@percent }
\newlabel{fig:final_train}{{9}{7}}
\@writefile{lot}{\contentsline {table}{\numberline {V}{\ignorespaces ANN predictions of the Tsai-wu and MS strength ratio with the numberical results obtained by CLT.\relax }}{7}\protected@file@percent }
\newlabel{tab:simu}{{V}{7}}
\bibstyle{IEEEtran}
\bibdata{src/a5_reference}
\bibcite{todoroki1998stacking}{1}
\bibcite{liu2000permutation}{2}
\bibcite{sivakumar1998optimum}{3}
\bibcite{walker2003technique}{4}
\bibcite{lin2004stacking}{5}
\bibcite{kang2005minimum}{6}
\bibcite{murugan2007target}{7}
\bibcite{akbulut2008optimum}{8}
\bibcite{YAN2020108014}{9}
\bibcite{MENTGES2021108736}{10}
\bibcite{lobo2007parameter}{11}
\bibcite{liu1996evolutionary}{12}
\bibcite{rodzin2016neuroevolution}{13}
\bibcite{massard1984computer}{14}
\bibcite{reddy1987first}{15}
\bibcite{fang1993design}{16}
\bibcite{soeiro1994multilevel}{17}
\bibcite{pelletier2006multi}{18}
\bibcite{jadhav2007parametric}{19}
\bibcite{omkar2008artificial}{20}
\bibcite{choudhury2019failure}{21}
\bibcite{watkins1987multicriteria}{22}
\bibcite{martin1987optimum}{23}
\bibcite{soares1995discrete}{24}
\bibcite{cybenko1989approximation}{25}
\bibcite{baker2017accelerating}{26}
\bibcite{lecun1989backpropagation}{27}
\@writefile{toc}{\contentsline {section}{\numberline {VII}Conclusion}{8}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{References}{8}\protected@file@percent }

The main challenge presented by the laminated composite design is the laminate
layup, involving a set of fiber orientations, composite material systems, and
stacking sequences. In practice, it can be formulate as a constrained
combinatorial optimization problems which can be solved by the genetic
algorithm. However, genetic algorithm is invented for unconstrained problem,
which means to use this algorithm you need convert a constrained problem to an
unconstrained problem, for example, appending punishment items to the objective
function. 

In the present study, Method without modifying the objective function is  
proposed for solving constrained problems, which is based on genetic algorithm
framework. We apply this strategy for both practical and theoretical problems in
the design of midplane-symmetric laminated composite material, respectively, in
which Tsai-wu criteria and maximum stress criteria are treated as two
constraints to decide whether the load-bearing capacity of a composite material
is exceeded or not. For the practical problem, we implement this strategy to
guide the design of cross-ply laminate, in which the fiber orientation are
consist of 0 and 90; then we compared the obtained results with other related
research. For the theoretical one, we also make use of this method to design
composite laminate with minimum thichness, in which the number of fiber
orientation used is limited. Numerical results are obtained and presented under
different loading cases.

Traditionally, classic lamination theory is widely used to compute
properties of composite materials under in-plane and out-of-plane loading from
a knowledge of the material properties of the individual layers and the
laminate geometry. In this study, a systematic procedure is proposed to design
an artificial neural network for a practical engineering problem, which is
applied to calculate the strength ratio of a laminated composite material under
in-plane loading, in which the genetic algorithm is proposed to optimize the search
process at four different levels: the architecture, parameters, connections of
the neural network, and active functions. 


